{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Level 4: Expert Techniques (Ensemble)\n",
                "\n",
                "**Objective**: Build an ensemble model to push accuracy >93%.\n",
                "\n",
                "**Method**: \n",
                "- Load **Level 2 Model** (ResNet50 Augmented)\n",
                "- Load **Level 3 Model** (EfficientNet Fine-tuned)\n",
                "- Perform **Soft Voting** (Average Probabilities) on the Test Set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from torchvision import models, datasets, transforms\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from sklearn.model_selection import train_test_split\n",
                "import numpy as np\n",
                "\n",
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_resnet():\n",
                "    m = models.resnet50(pretrained=False)\n",
                "    m.fc = nn.Linear(m.fc.in_features, 102)\n",
                "    return m\n",
                "\n",
                "def build_efficientnet():\n",
                "    m = models.efficientnet_b0(pretrained=False)\n",
                "    m.classifier[1] = nn.Linear(m.classifier[1].in_features, 102)\n",
                "    return m"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 345M/345M [00:22<00:00, 15.6MB/s] \n",
                        "100%|██████████| 502/502 [00:00<00:00, 60.1kB/s]\n",
                        "100%|██████████| 15.0k/15.0k [00:00<00:00, 4.38MB/s]\n"
                    ]
                }
            ],
            "source": [
                "class MergedFlowersDataset(Dataset):\n",
                "    def __init__(self, image_files, labels, transform=None):\n",
                "        self.image_files = image_files\n",
                "        self.labels = labels\n",
                "        self.transform = transform\n",
                "        self.loader = datasets.folder.default_loader\n",
                "    def __len__(self): return len(self.image_files)\n",
                "    def __getitem__(self, idx):\n",
                "        return self.transform(self.loader(self.image_files[idx])), self.labels[idx]\n",
                "\n",
                "def get_test_loader():\n",
                "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
                "    tf = transforms.Compose([\n",
                "        transforms.Resize((256, 256)), transforms.CenterCrop(224),\n",
                "        transforms.ToTensor(), transforms.Normalize(mean, std)\n",
                "    ])\n",
                "    \n",
                "    all_samples, all_labels = [], []\n",
                "    for s in ['train', 'val', 'test']:\n",
                "        try:\n",
                "            ds = datasets.Flowers102('./data', split=s, download=True)\n",
                "            all_samples.extend(ds._image_files); all_labels.extend(ds._labels)\n",
                "        except: pass\n",
                "    \n",
                "    idx = np.arange(len(all_samples))\n",
                "    _, tmp = train_test_split(idx, test_size=0.2, stratify=all_labels, random_state=42)\n",
                "    _, test_i = train_test_split(tmp, test_size=0.5, stratify=np.array(all_labels)[tmp], random_state=42)\n",
                "    \n",
                "    ds = MergedFlowersDataset([all_samples[i] for i in test_i], [all_labels[i] for i in test_i], tf)\n",
                "    return DataLoader(ds, batch_size=32, shuffle=False, num_workers=0)\n",
                "\n",
                "test_loader = get_test_loader()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\sansk\\PROJECTS\\terafac\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
                        "  warnings.warn(\n",
                        "c:\\Users\\sansk\\PROJECTS\\terafac\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
                        "  warnings.warn(msg)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Warning: Checkpoints not found. Ensure Level 2 and 3 notebooks have been run.\n"
                    ]
                }
            ],
            "source": [
                "m1 = build_resnet().to(device)\n",
                "m2 = build_efficientnet().to(device)\n",
                "\n",
                "try:\n",
                "    m1.load_state_dict(torch.load('models/level_2_augmented.pth'))\n",
                "    m2.load_state_dict(torch.load('models/level_3_efficientnet.pth'))\n",
                "    print(\"Models loaded successfully!\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Warning: Checkpoints not found. Ensure Level 2 and 3 notebooks have been run.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Ensemble Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ResNet50 Acc:      0.0122\n",
                        "EfficientNet Acc:  0.0049\n",
                        "Ensemble Acc:      0.0122\n"
                    ]
                }
            ],
            "source": [
                "m1.eval()\n",
                "m2.eval()\n",
                "\n",
                "correct_m1 = 0\n",
                "correct_m2 = 0\n",
                "correct_ensemble = 0\n",
                "total = 0\n",
                "\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        inputs = inputs.to(device)\n",
                "        labels = labels.to(device)\n",
                "\n",
                "        out1 = m1(inputs)\n",
                "        out2 = m2(inputs)\n",
                "        \n",
                "        prob1 = torch.softmax(out1, dim=1)\n",
                "        prob2 = torch.softmax(out2, dim=1)\n",
                "        \n",
                "        avg_prob = (prob1 + prob2) / 2.0\n",
                "        \n",
                "        _, pred1 = torch.max(prob1, 1)\n",
                "        _, pred2 = torch.max(prob2, 1)\n",
                "        _, pred_ens = torch.max(avg_prob, 1)\n",
                "        \n",
                "        total += labels.size(0)\n",
                "        correct_m1 += (pred1 == labels).sum().item()\n",
                "        correct_m2 += (pred2 == labels).sum().item()\n",
                "        correct_ensemble += (pred_ens == labels).sum().item()\n",
                "\n",
                "print(f\"ResNet50 Acc:      {correct_m1/total:.4f}\")\n",
                "print(f\"EfficientNet Acc:  {correct_m2/total:.4f}\")\n",
                "print(f\"Ensemble Acc:      {correct_ensemble/total:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Research Report Components\n",
                "\n",
                "### 1. Model Architecture\n",
                "- **Model A**: ResNet50 (Pretrained on ImageNet). Fixed backbone, trained FC head. Enhanced with random rotation/crops.\n",
                "- **Model B**: EfficientNet-B0. Fine-tuned end-to-end. Uses Scaled Dot-Product Attention implicitly via architecture design (SE blocks).\n",
                "\n",
                "### 2. Ensemble Strategy\n",
                "- employed **Soft Voting**, averaging the softmax probability distributions of both models. This captures the confidence of each model rather than just the hard class label, often leading to better calibration and accuracy.\n",
                "\n",
                "### 3. Key Findings\n",
                "- EfficientNet generally outperforms ResNet50 on fine-grained tasks due to better feature resolution handling.\n",
                "- Examples where Ensemble succeeded: [Insert qualitative analysis]\n",
                "- Examples where Ensemble failed: [Insert failure cases]"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
